{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d0176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Message: Failed to decode response from marionette\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import speeches from al-manasa website using selenium library with defining story number because of scrolling boundaries on website\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Define the URL of the main page containing links to speeches\n",
    "main_page_url = \"https://almanassa.com/columns/president-speeches\"\n",
    "\n",
    "try:\n",
    "    # Initialize the Selenium WebDriver for Firefox (GeckoDriver)\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    # Navigate to the main page\n",
    "    driver.get(main_page_url)\n",
    "\n",
    "    # Scroll down the page to load more content (you can repeat this as many times as needed)\n",
    "    for _ in range(5):  # Adjust the number of scrolls as needed\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)  # Wait for the content to load\n",
    "\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Find all links to individual speeches on the main page\n",
    "    speech_links = soup.find_all(\"a\", class_=\"overlay-link\")\n",
    "\n",
    "    if speech_links:\n",
    "        # Start numbering from 385\n",
    "        start_number = 385\n",
    "\n",
    "        # Iterate through the speech links\n",
    "        for speech_link in speech_links:\n",
    "            # Get the URL of the speech\n",
    "            speech_url = speech_link[\"href\"]\n",
    "            \n",
    "            # Extract the story number from the URL\n",
    "            story_number = int(re.search(r'/stories/(\\d+)', speech_url).group(1))\n",
    "            \n",
    "            # Check if the story number is less than 4686\n",
    "            if story_number < 4686:\n",
    "                # Increment the start_number\n",
    "                start_number += 1\n",
    "            else:\n",
    "                # Skip stories with numbers greater than or equal to 4686\n",
    "                continue\n",
    "\n",
    "            # Check if the speech_url is a relative URL and make it an absolute URL\n",
    "            if not speech_url.startswith(\"http\"):\n",
    "                speech_url = urljoin(\"https://almanassa.com\", speech_url)\n",
    "\n",
    "            # Navigate to the speech page\n",
    "            driver.get(speech_url)\n",
    "\n",
    "            # Parse the HTML content of the speech page\n",
    "            speech_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # Rest of your code...\n",
    "\n",
    "    else:\n",
    "        print(\"Speech links not found on the main page. Please inspect the webpage structure.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the Selenium WebDriver\n",
    "    if 'driver' in locals():\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e18488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading speeches and categorizing them by year based on the date in the speech title\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "\n",
    "# Define the directory containing your text files\n",
    "directory_path = '/path/to/your/text/files/'\n",
    "\n",
    "# Create a dictionary to store files by year\n",
    "files_by_year = defaultdict(list)\n",
    "\n",
    "# Regular expression pattern to extract dates in the format \"dd/mm/yyyy\"\n",
    "date_pattern = r'\\d{1,2}/\\d{1,2}/\\d{4}'\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    \n",
    "    # Check if the file is a text file (you can modify this check as needed)\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "            # Extract the date from the title using regular expression\n",
    "            match = re.search(date_pattern, content)\n",
    "            if match:\n",
    "                date_str = match.group()\n",
    "                year = date_str.split('/')[-1]\n",
    "                files_by_year[year].append(filename)\n",
    "\n",
    "# Create directories for each year and move the corresponding files\n",
    "for year, filenames in files_by_year.items():\n",
    "    year_directory = os.path.join(directory_path, year)\n",
    "    os.makedirs(year_directory, exist_ok=True)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        old_path = os.path.join(directory_path, filename)\n",
    "        new_path = os.path.join(year_directory, filename)\n",
    "        shutil.move(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709f9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract metadata of the speeches (title, date, and place) and save them in csv file using regular expressions\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Define the directory containing your text files\n",
    "directory_path = 'speeches/2023/'\n",
    "\n",
    "# Regular expression patterns to extract the title, date, and place\n",
    "title_pattern = r'^(.*?)\\s\\d{1,2}/\\d{1,2}/\\d{4}'  # Extracts everything before the date\n",
    "date_pattern = r'(\\d{1,2}/\\d{1,2}/\\d{4})'  # Extracts the date\n",
    "place_pattern = r'ألقيت الكلمة في (\\S+(?:\\s+\\S+)?)|في (?:محافظة|مدينة|أكاديمية|الأكاديمية) (\\S+(?:\\s+\\S+)?)'  # Extracts the place after specified phrases\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = 'speeches/2023/speech2023_metadata.csv'\n",
    "\n",
    "# Initialize the CSV file (create it if it doesn't exist)\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    fieldnames = ['File Name', 'Title', 'Date', 'Place']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Read the content of the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Use regular expressions to extract the metadata\n",
    "        title_match = re.search(title_pattern, content)\n",
    "        date_match = re.search(date_pattern, content)\n",
    "        place_match = re.search(place_pattern, content)\n",
    "\n",
    "        # Extracted metadata\n",
    "        if title_match:\n",
    "            title = title_match.group(1)\n",
    "        else:\n",
    "            title = None\n",
    "\n",
    "        if date_match:\n",
    "            date = date_match.group(1)\n",
    "        else:\n",
    "            date = None\n",
    "\n",
    "        if place_match:\n",
    "            place = place_match.group(1) or place_match.group(2)\n",
    "        else:\n",
    "            place = None\n",
    "\n",
    "        # Append the metadata to the CSV file, including the file name\n",
    "        with open(csv_file_path, mode='a', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writerow({'File Name': filename, 'Title': title, 'Date': date, 'Place': place})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc91d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
